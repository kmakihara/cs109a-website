{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xlrd\n",
    "import csv\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: Scrape Data from XLS, Clean CSV's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Clean FBI and Census Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fbi_data_path = 'Crime/data/fbi_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to convert xls to csv\n",
    "def xls_to_csv(wb, csv_name):\n",
    "    wb = xlrd.open_workbook(wb)\n",
    "    sh = wb.sheet_by_index(0)\n",
    "    output_file = open('{}.csv'.format(csv_name), 'w')\n",
    "    wr = csv.writer(output_file, quoting=csv.QUOTE_ALL)\n",
    "\n",
    "    for rownum in range(sh.nrows):\n",
    "        wr.writerow(sh.row_values(rownum))\n",
    "\n",
    "    output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to extract crime_stats from csv files\n",
    "def get_crime_stats(df_path):\n",
    "    df = pd.read_csv(df_path, skiprows=3)\n",
    "    df['Metropolitan Statistical Area'] = df['Metropolitan Statistical Area'].fillna(method='ffill')\n",
    "    crime_stats = df[df['Counties/principal cities'] == 'Total area actually reporting']\n",
    "    crime_stats = crime_stats.drop(['Counties/principal cities', 'Population'], axis=1)\n",
    "    columns = list(map(lambda x: '_'.join(x.split()), crime_stats.columns))\n",
    "    crime_stats.columns = columns\n",
    "    crime_stats['Metropolitan_Statistical_Area'] = crime_stats['Metropolitan_Statistical_Area'].apply(lambda x: x.split('M.S.A')[0].strip())\n",
    "    mask = crime_stats['Metropolitan_Statistical_Area'].apply(lambda x: 'M.D' not in x)\n",
    "    crime_stats = crime_stats[mask]\n",
    "    crime_stats = pd.DataFrame(crime_stats[['Metropolitan_Statistical_Area', 'Murder_and_nonnegligent_manslaughter']])\n",
    "    return crime_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fbi_filepaths = [f for f in listdir(fbi_data_path) if isfile(join(fbi_data_path, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert xls to csv\n",
    "for f in fbi_filepaths:\n",
    "    file_path = join(fbi_data_path, f)\n",
    "    output_path = 'csvs/{}'.format(f[:-4])\n",
    "    xls_to_csv(file_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv_filepaths = [f for f in listdir('csvs/') if isfile(join('csvs/', f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(join('csvs/', csv_filepaths[0]), skiprows=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Extract relevant crime data and save to csv\n",
    "for f in csv_filepaths:\n",
    "    file_path = join('csvs/', f)\n",
    "    df = get_crime_stats(file_path)\n",
    "    for col in df.columns:\n",
    "        if 'Unnamed' in col:\n",
    "            df = df.drop(col, axis=1)\n",
    "    df.to_csv('csvs/{}.csv'.format(f[:-4]), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description of Data\n",
    "\n",
    "Both datasets are continuous, with counts in certain buckets. The data is not extremely difficult to deal with, though it does require some cleaning and conversion. Data from the FBI database is downloaded in XLS format, which is then parsed into a CSV. The CSV is then cleaned to only keep relevant bits of information, specifically the murder counts/\n",
    "\n",
    "The Census data is downloaded in a big CSV file form. This information is cleaner and more standardized, since it is already in csv form. However, there are still issues of missing values here and there. When combining each dataframe into a single joint one, we do an inner join on the MSA's present in each dataset. This is because each data set is only as useful as the other data set. This also means we need to be extra stringent when it comes to parsing the MSA names, so we don't lose too much data. Whenever there is a NaN value, we either drop it or set it to 0, depending on the situation. If it is a percentage category, then we set it to 0, since there are likely other categories with positive percentages.\n",
    "\n",
    "This data is cleaned, but only in a cursory fashion to perform EDA. As we venture into training our model, we will look into some more one-hot encoding, as well as potential classification measures (judging an area as low risk, medium risk, high risk etc...)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 1.2 Clean Additional Data, ATF reports on gun recoveries and sources by state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "atf_data_path = 'Crime/data/atf_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "atf_filepaths = [f for f in listdir(atf_data_path) if isfile(join(atf_data_path, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert atf xls to csv\n",
    "for f in atf_filepaths:\n",
    "    file_path = join(atf_data_path, f)\n",
    "    output_path = 'atf_csvs/{}'.format(f[-9:-5])\n",
    "    xls_to_csv(file_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "atf_csvs = [f for f in listdir('atf_csvs') if isfile(join('atf_csvs', f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frames = []\n",
    "for f in atf_csvs:\n",
    "    file_path = join('atf_csvs', f)\n",
    "    output_path = 'atf_csvs/{}'.format(f[:-4])\n",
    "    df = pd.read_csv(file_path, skiprows=1)\n",
    "    col_one = df.columns[0]\n",
    "    col_two = df.columns[1]\n",
    "    df = df.drop(col_one, axis=1)\n",
    "    df = df.rename(index=str, columns={col_two: 'Source State'})\n",
    "    df = df.dropna()\n",
    "    frames.append(df.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace states with their abbreviations\n",
    "states = [\n",
    "            ['Arizona', 'AZ'],\n",
    "            ['Alabama', 'AL'],\n",
    "            ['Alaska', 'AK'],\n",
    "            ['Arkansas', 'AR'],\n",
    "            ['California', 'CA'],\n",
    "            ['Colorado', 'CO'],\n",
    "            ['Connecticut', 'CT'],\n",
    "            ['Delaware', 'DE'],\n",
    "            ['Florida', 'FL'],\n",
    "            ['Georgia', 'GA'],\n",
    "            ['Hawaii', 'HI'],\n",
    "            ['Idaho', 'ID'],\n",
    "            ['Illinois', 'IL'],\n",
    "            ['Indiana', 'IN'],\n",
    "            ['Iowa', 'IA'],\n",
    "            ['Kansas', 'KS'],\n",
    "            ['Kentucky', 'KY'],\n",
    "            ['Louisiana', 'LA'],\n",
    "            ['Maine', 'ME'],\n",
    "            ['Maryland', 'MD'],\n",
    "            ['Massachusetts', 'MA'],\n",
    "            ['Michigan', 'MI'],\n",
    "            ['Minnesota', 'MN'],\n",
    "            ['Mississippi', 'MS'],\n",
    "            ['Missouri', 'MO'],\n",
    "            ['Montana', 'MT'],\n",
    "            ['Nebraska', 'NE'],\n",
    "            ['Nevada', 'NV'],\n",
    "            ['New Hampshire', 'NH'],\n",
    "            ['New Jersey', 'NJ'],\n",
    "            ['New Mexico', 'NM'],\n",
    "            ['New York', 'NY'],\n",
    "            ['North Carolina', 'NC'],\n",
    "            ['North Dakota', 'ND'],\n",
    "            ['Ohio', 'OH'],\n",
    "            ['Oklahoma', 'OK'],\n",
    "            ['Oregon', 'OR'],\n",
    "            ['Pennsylvania', 'PA'],\n",
    "            ['Rhode Island', 'RI'],\n",
    "            ['South Carolina', 'SC'],\n",
    "            ['South Dakota', 'SD'],\n",
    "            ['Tennessee', 'TN'],\n",
    "            ['Texas', 'TX'],\n",
    "            ['Utah', 'UT'],\n",
    "            ['Vermont', 'VT'],\n",
    "            ['Virginia', 'VA'],\n",
    "            ['Washington', 'WA'],\n",
    "            ['West Virginia', 'WV'],\n",
    "            ['Wisconsin', 'WI'],\n",
    "            ['Wyoming', 'WY'],\n",
    "        ]\n",
    "\n",
    "states = list(map(lambda x: [x[0].lower(), x[1]], states))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "states.append(['district of columbia', 'DC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def abbreviate(state_name, state_list=states):\n",
    "    lowercase = state_name.lower()\n",
    "    abbreviation = [x[1] for x in state_list if x[0] == lowercase]\n",
    "    if len(abbreviation) > 0:\n",
    "        return abbreviation[0]\n",
    "    else:\n",
    "        return state_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cleaned_frames = []\n",
    "for i, frame in enumerate(frames):\n",
    "    df_left = pd.DataFrame(frame['Source State'])\n",
    "    source_totals = frame.columns[-1]\n",
    "    df_left['Total Sourced'] = frame[source_totals]\n",
    "    recovery_totals = frame['Source State'][-1]\n",
    "    df_right = frame[frame['Source State'] == recovery_totals].T\n",
    "    df = pd.merge(df_left, df_right, left_on='Source State', right_index=True)\n",
    "    cols = ['State', 'Total Sourced', 'Total Recovered']\n",
    "    df.columns = cols\n",
    "    df['State'] = df['State'].apply(abbreviate, state_list=states)\n",
    "    cleaned_frames.append(df)\n",
    "    df.to_csv(join('atf_csvs', atf_csvs[i]), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I recover and clean data from the ATF database. There are 3 columns in this df: state, total sourced, and total recovered. Total sourced is the number of firearms the ATF recovered in that year that were sourced from that state. Similarly, the total recovered is the number of firearms the ATF recovered in that state. I also abbreviated each state because that is the format in the MSA analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
